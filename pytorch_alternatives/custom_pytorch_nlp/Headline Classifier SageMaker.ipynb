{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End NLP: News Headline Classifier (SageMaker Version)\n",
    "\n",
    "This notebook trains a Keras-based model to classify news headlines between four domains: Business (b), Entertainment (e), Health & Medicine (m) and Science & Technology (t).\n",
    "\n",
    "Following on from the previous local-mode notebook, we show how to trigger the model training and deployment on separate infrastructure - to make better use of resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Execution Role and Session\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region. \n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the **get_execution_role** method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::344028372807:role/service-role/AmazonSageMaker-ExecutionRole-20190212T154595\n",
      "CPU times: user 903 ms, sys: 80.8 ms, total: 984 ms\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download News Aggregator Dataset\n",
    "\n",
    "The News Aggregator Dataset is available at the public **UCI Machine Learning Database** repository (these files should already be downloaded in previous notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Downloading data...\n",
      "Saved to data/ folder\n"
     ]
    }
   ],
   "source": [
    "import util.preprocessing\n",
    "\n",
    "util.preprocessing.download_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the dataset\n",
    "\n",
    "We will load the newsCorpora.csv file to a Pandas dataframe for our data processing work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "1  Fed official says weak data caused by weather,...   \n",
       "2  Fed's Charles Plosser sees high bar for change...   \n",
       "3  US open: Stocks fall after Fed official hints ...   \n",
       "4  Fed risks falling 'behind the curve', Charles ...   \n",
       "5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "df = pd.read_csv(\"data/newsCorpora.csv\", names=column_names, header=None, delimiter=\"\\t\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we'll **only use**:\n",
    "\n",
    "- The **title** (Headline) of the news story, as our input\n",
    "- The **category**, as our target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    152469\n",
       "b    115967\n",
       "t    108344\n",
       "m     45639\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has four article categories: Business (b), Entertainment (e), Health & Medicine (m) and Science & Technology (t).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Pre-Processing\n",
    "\n",
    "We'll do some basic processing of the text data to convert it into numerical form that the algorithm will be able to consume to create a model.\n",
    "\n",
    "We will do typical pre processing for NLP workloads such as: dummy encoding the labels, tokenizing the documents and set fixed sequence lengths for input feature dimension, padding documents to have fixed length input vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Encode the Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'e' 'm' 't']\n"
     ]
    }
   ],
   "source": [
    "encoded_y, labels = util.preprocessing.dummy_encode_labels(df, \"CATEGORY\")\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Set Fixed Sequence Lengths\n",
    "\n",
    "We want to describe our inputs at the more meaningful word level (rather than individual characters), and ensure a fixed length of the input feature dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 75286\n",
      "Number of headlines: 422419\n"
     ]
    }
   ],
   "source": [
    "padded_docs, tokenizer = util.preprocessing.tokenize_pad_docs(df, \"TITLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fed official says weak data caused by weather, should not slow taper'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"TITLE\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 215,  452,   25, 1062,   84, 1970,   19, 1081,  270,   37, 1412,\n",
       "       7900,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Word Embeddings\n",
    "\n",
    "To represent our words in numeric form, we'll use pre-trained vector representations for each word in the vocabulary: In this case we'll be using pre-built GloVe word embeddings.\n",
    "\n",
    "You could also explore training custom, domain-specific word embeddings using SageMaker's built-in [BlazingText algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html). See the official [blazingtext_word2vec_text8 sample](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/blazingtext_word2vec_text8) for an example notebook showing how.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Glove word embeddings...\n",
      "Unzipping...\n",
      "Loading into memory...\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = util.preprocessing.get_word_embeddings(tokenizer, \"data/embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 100)\n"
     ]
    }
   ],
   "source": [
    "np.save(\n",
    "    file=\"./data/embeddings/docs-embedding-matrix\",\n",
    "    arr=embedding_matrix,\n",
    "    allow_pickle=False,\n",
    ")\n",
    "vocab_size=embedding_matrix.shape[0]\n",
    "print(embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets\n",
    "\n",
    "Finally we need to divide our data into model training and evaluation sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_docs,\n",
    "    encoded_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/train\", exist_ok=True)\n",
    "np.save(\"./data/train/train_X.npy\", X_train)\n",
    "np.save(\"./data/train/train_Y.npy\", y_train)\n",
    "os.makedirs(\"./data/test\", exist_ok=True)\n",
    "np.save(\"./data/test/test_X.npy\", X_test)\n",
    "np.save(\"./data/test/test_Y.npy\", y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3\n",
    "\n",
    "We'll need to upload our processed data to S3 to make it available for SageMaker training jobs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sess.default_bucket()\n",
    "s3_prefix = \"news\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_s3_prefix = f\"{s3_prefix}/data/train\"\n",
    "testdata_s3_prefix = f\"{s3_prefix}/data/test\"\n",
    "embeddings_s3_prefix = f\"{s3_prefix}/data/embeddings\"\n",
    "output_s3 = f\"s3://{s3_bucket}/{s3_prefix}/models/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = sess.upload_data(path=\"./data/train/\", bucket=s3_bucket, key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path=\"./data/test/\", bucket=s3_bucket, key_prefix=testdata_s3_prefix)\n",
    "embeddings_s3 = sess.upload_data(\n",
    "    # Only send the numpy array of embeddings, not the original files as well:\n",
    "    path=\"./data/embeddings/docs-embedding-matrix.npy\",\n",
    "    bucket=s3_bucket,\n",
    "    key_prefix=embeddings_s3_prefix,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 's3://sagemaker-ap-southeast-1-344028372807/news/data/train', 'test': 's3://sagemaker-ap-southeast-1-344028372807/news/data/test', 'embeddings': 's3://sagemaker-ap-southeast-1-344028372807/news/data/embeddings/docs-embedding-matrix.npy'}\n"
     ]
    }
   ],
   "source": [
    "inputs = { \"train\": train_s3, \"test\": test_s3, \"embeddings\": embeddings_s3 }\n",
    "print(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Differentiated Infrastructure on Sagemaker\n",
    "\n",
    "This time, we've packaged the model build and train code from our previous notebook ([Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb)) into the [**main.py**](src/main.py) script in the **src** directory.\n",
    "\n",
    "We'll use the high-level TensorFlow SDK to train our model on SageMaker.\n",
    "\n",
    "You can explore the script file for more details on the interface.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Amazon SageMaker runs your Tensorflow script with pre-built containers\n",
    "\n",
    "Amazon Sagemaker has pre packaged a set of Docker images to help you accelerate building your projects. This what is driving the Sagemkaer Tensorflow Estimator. You can use the same Tensorflow image for training and/or hosting. You can find more information in the following: https://github.com/aws/sagemaker-tensorflow-container , https://sagemaker.readthedocs.io/en/stable/using_tf.html , https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html .\n",
    "\n",
    "\n",
    "#### Running your container during training\n",
    "\n",
    "When Amazon SageMaker runs training, your training script (entry_point input) is run just like a regular Python program. A number of files are laid out for your use, under a `/opt/ml` directory. These will be locations that you can access from within your script. You will see an example of the use of this in our [**main.py**](src/main.py) :\n",
    "\n",
    "    /opt/ml\n",
    "    |-- code\n",
    "    |   `-- <our script(s)>\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "\n",
    "##### The input\n",
    "\n",
    "* `/opt/ml/input/config` contains information to control how your program runs. `hyperparameters.json` is a JSON-formatted dictionary of hyperparameter names to values. These values will always be strings, so you may need to convert them. `resourceConfig.json` is a JSON-formatted file that describes the network layout used for distributed training. Since scikit-learn doesn't support distributed training, we'll ignore it here.\n",
    "* `/opt/ml/input/data/<channel_name>/` (for File mode) contains the input data for that channel. The channels are created based on the call to CreateTrainingJob but it's generally important that channels match what the algorithm expects. The files for each channel will be copied from S3 to this directory, preserving the tree structure indicated by the S3 key structure. \n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (for Pipe mode) is the pipe for a given epoch. Epochs start at zero and go up by one each time you read them. There is no limit to the number of epochs that you can run, but you must close each pipe before reading the next epoch.\n",
    "\n",
    "##### The output\n",
    "\n",
    "* `/opt/ml/model/` is the directory where you write the model that your algorithm generates. Your model can be in any format that you want. It can be a single file or a whole directory tree. SageMaker will package any files in this directory into a compressed tar archive file. This file will be available at the S3 location returned in the `DescribeTrainingJob` result.\n",
    "* `/opt/ml/output` is a directory where the algorithm can write a file `failure` that describes why the job failed. The contents of this file will be returned in the `FailureReason` field of the `DescribeTrainingJob` result. For jobs that succeed, there is no reason to write this file as it will be ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the script will run on a separate container, we can pass whatever parameters it needs through SageMaker:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { \"epochs\": 1, \"vocab_size\": vocab_size, \"num_classes\": 4 }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our `TensorFlow` estimator object, we have set the hyper-parameters for this object and we have our data channels linked with the algorithm. The only  remaining thing to do is to train the algorithm. The following command will train the algorithm. Training the algorithm involves a few steps. Firstly, the instance that we requested while creating the `TensorFlow` estimator classes is provisioned and is setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take some time, depending on the size of the data. \n",
    "\n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as `output_path` in the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the training job using a ml.p3.2xlarge instance (GPUs) to accelerate our training. If your account runs into resource limits please use a ml.c5.xlarge instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmppsvovba5_algo-1-n8109_1 ... \n",
      "\u001b[1BAttaching to tmppsvovba5_algo-1-n8109_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:09,904 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:09,906 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:09,918 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:09,924 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:11,084 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:11,098 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:11,112 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:11,124 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"embeddings\": \"/opt/ml/input/data/embeddings\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"current_host\": \"algo-1-n8109\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"algo-1-n8109\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"vocab_size\": 400000,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"num_classes\": 4\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"embeddings\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"job_name\": \"news-pytorch-2020-09-20-14-53-58-585\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"master_hostname\": \"algo-1-n8109\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-southeast-1-344028372807/news-pytorch-2020-09-20-14-53-58-585/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"module_name\": \"main\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"current_host\": \"algo-1-n8109\",\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m             \"algo-1-n8109\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m     \"user_entry_point\": \"main.py\"\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_HOSTS=[\"algo-1-n8109\"]\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_HPS={\"epochs\":1,\"num_classes\":4,\"vocab_size\":400000}\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_USER_ENTRY_POINT=main.py\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-n8109\",\"hosts\":[\"algo-1-n8109\"]}\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"embeddings\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_CHANNELS=[\"embeddings\",\"test\",\"train\"]\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_CURRENT_HOST=algo-1-n8109\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_MODULE_NAME=main\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-southeast-1-344028372807/news-pytorch-2020-09-20-14-53-58-585/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"embeddings\":\"/opt/ml/input/data/embeddings\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-n8109\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-n8109\"],\"hyperparameters\":{\"epochs\":1,\"num_classes\":4,\"vocab_size\":400000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"embeddings\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"news-pytorch-2020-09-20-14-53-58-585\",\"log_level\":20,\"master_hostname\":\"algo-1-n8109\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-344028372807/news-pytorch-2020-09-20-14-53-58-585/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-n8109\",\"hosts\":[\"algo-1-n8109\"]},\"user_entry_point\":\"main.py\"}\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--num_classes\",\"4\",\"--vocab_size\",\"400000\"]\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_CHANNEL_EMBEDDINGS=/opt/ml/input/data/embeddings\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_HP_VOCAB_SIZE=400000\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m SM_HP_NUM_CLASSES=4\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m /opt/conda/bin/python main.py --epochs 1 --num_classes 4 --vocab_size 400000\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m \n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m there\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 1\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 3\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 4\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 5\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 6\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 7\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 8\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 9\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 10\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 11\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 12\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 13\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 14\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 15\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 16\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 17\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 18\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 19\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 20\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 21\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 22\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 23\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 24\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 25\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 26\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 27\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 28\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 29\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 30\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 31\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 32\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 33\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 34\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 35\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 36\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 37\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 38\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 40\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 41\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 42\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 43\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 44\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 45\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 46\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 47\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 48\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 49\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 50\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 51\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 52\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 53\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 54\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 55\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 56\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 57\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 58\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 59\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 60\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 61\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 62\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 63\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 64\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 65\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 66\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 67\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 68\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 69\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 70\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 71\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 72\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 73\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 74\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 75\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 76\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 77\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 78\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 79\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 80\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 81\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 82\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 83\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 84\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 85\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 86\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 87\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 88\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 89\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 90\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 91\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 92\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 93\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 94\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 95\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 96\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 97\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 98\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 99\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 100\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 101\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 102\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 103\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 104\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 105\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 106\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 107\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 108\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 109\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 110\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 111\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 112\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 113\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 114\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 115\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 116\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 117\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 118\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 119\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 120\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 121\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 122\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 123\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 124\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 125\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 126\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 127\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 128\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 129\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 130\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 131\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 132\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 133\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 134\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 135\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 136\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 137\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 138\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 139\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 140\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 141\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 142\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 143\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 144\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 145\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 146\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 147\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 148\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 149\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 150\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 151\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 152\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 153\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 154\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 155\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 156\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 157\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 158\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 159\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 160\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 161\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 162\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 163\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 164\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 165\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 166\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 167\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 168\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 169\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 170\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 171\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 172\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 173\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 174\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 175\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 176\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 177\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 178\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 179\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 180\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 181\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 182\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 183\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 184\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 185\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 186\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 187\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 188\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 189\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 190\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 191\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 192\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 193\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 194\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 195\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 196\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 197\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 198\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 199\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 200\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m Evaluating model\n",
      "\u001b[36malgo-1-n8109_1  |\u001b[0m 2020-09-20 14:54:14,487 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmppsvovba5_algo-1-n8109_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"main.py\",\n",
    "    source_dir=\"./src\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"local\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=[\n",
    "       { \"Name\": \"Epoch\", \"Regex\": \"epoch: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"Train:Loss\", \"Regex\": \"train_loss: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"Validation:Loss\", \"Regex\": \"val_loss=([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"Validation:Accuracy\", \"Regex\": \"val_acc=([0-9\\\\.]+)\" },\n",
    "    ],\n",
    "    base_job_name=\"news-pytorch\",\n",
    "    #train_use_spot_instances=True,       # Use spot instances to reduce cost\n",
    "    #train_max_run=20*60,                 # Maximum allowed active runtime\n",
    "    #train_max_wait=30*60,                # Maximum clock time (including spot delays)\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training job is running take a minute to look at the `main.py` script. You can see how we have adapted the our original local code from [Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb) to run on Sagemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model: Hosting / Inference\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same type of instance that we used to train. Because instance endpoints will be up and running for long, it's advisable to choose a cheaper instance for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (**JupyterLab Only**) Installing IPyWidgets Extension\n",
    "\n",
    "This notebook uses a fun little interactive widget to query the classifier, so **ONLY if you're using JupyterLab** (no action needed for plain Jupyter users) you'll need to install an extension to enable it:\n",
    "\n",
    "- Select \"*Settings > Enable Extension Manager (experimental)*\" from the toolbar, and confirm to enable it\n",
    "- Click on the new jigsaw puzzle piece icon in the sidebar, to open the Extension Manager\n",
    "- Search for `@jupyter-widgets/jupyterlab-manager` (Scroll down - search results show up *below* the list of currently installed widgets!)\n",
    "- Click \"**Install**\" below the widget's description\n",
    "- Wait for the blue progress bar that appears by the search box\n",
    "- You should be prompted \"*A build is needed to include the latest changes*\" - select \"**Rebuild**\"\n",
    "- The progress bar should resume, and you should shortly see a \"Build Complete\" dialogue.\n",
    "- Select \"**Reload**\" to reload the webpage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your model should now be in production as a RESTful API!\n",
    "\n",
    "Let's evaluate our model with some example headlines...\n",
    "\n",
    "If you struggle with the widget, you can always simply call the `classify()` function from Python.\n",
    "\n",
    "You can be creative with your headlines!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee16e7100af41b9ad9321212d924744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='The markets were bullish after news of the merger', description='Headline:',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def classify(text):\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    encoded_example = tokenizer.texts_to_sequences([text])\n",
    "    # Pad documents to a max length of 40 words\n",
    "    max_length = 40\n",
    "    padded_example = pad_sequences(encoded_example, maxlen=max_length, padding=\"post\")\n",
    "    result = predictor.predict(padded_example.tolist())\n",
    "    print(result)\n",
    "    ix = np.argmax(result[\"predictions\"])\n",
    "    print(f\"Predicted class: '{labels[ix]}' with confidence {result['predictions'][0][ix]:.2%}\")\n",
    "\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    )\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Unlike training jobs (which destroy their resources as soon as training is finished), real-time endpoint deployments provision instances until we specifically shut the endpoint down...\n",
    "\n",
    "So let's be frugal with resources, and delete resources when we don't need them anymore:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Automatic Hyperparameter Optimization - HPO\n",
    "\n",
    "Rather than manually tweak parameters to tune the model performance, we can get SageMaker to help us out.\n",
    "\n",
    "We'll simply tell SageMaker:\n",
    "\n",
    "- The type and allowable range of each parameter,\n",
    "- The metric we want to optimize for, and\n",
    "- Strategy and resource constraints\n",
    "\n",
    "...and the service will set up jobs for us to find the best combination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Hyper-)Parameter Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner, IntegerParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(2, 7),\n",
    "    \"learning_rate\": ContinuousParameter(0.01, 0.2),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Metric\n",
    "\n",
    "'Metrics' in SageMaker are scraped from the console output of jobs, by way of regular expressions.\n",
    "\n",
    "We can define multiple metrics to monitor, but HPO requires us to specify that exactly one of them is the **objective** metric to optimize:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{ \"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\" }]\n",
    "objective_metric_name = \"loss\"\n",
    "objective_type = \"Minimize\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Tuning Job\n",
    "\n",
    "We already defined our Estimator above, so we'll just re-use the configuration with minor adjustments.\n",
    "\n",
    "Note that the Estimator's `hyperparameters` will be used as base values, and overridden by the HyperParameterTuner where appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep per-job resources modest, so that parallel jobs don't hit any limits:\n",
    "estimator.train_instance_type = \"ml.c5.xlarge\"\n",
    "estimator.train_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    base_tuning_job_name=\"news-hpo-keras\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type\n",
    ")\n",
    "\n",
    "tuner.fit(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check On Progress\n",
    "\n",
    "HPO jobs can take a long time to complete, and can run multiple training jobs in parallel - each on multiple instances... Which is why the `fit()` call above doesn't wait by default, and won't show us a potentially-confusing consolidated log stream.\n",
    "\n",
    "Go to the Training > Hyperparameter Tuning Jobs page of the [**SageMaker Console**](https://console.aws.amazon.com/sagemaker/home#/hyper-tuning-jobs) and select the job from the list.\n",
    "\n",
    "You can see all the training jobs triggered for the HPO run, as well as overall summary metrics.\n",
    "\n",
    "This information can be accessed via the API/SDKs too of course. For example we can wait for HPO to finish like the below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Wait until HPO is finished\n",
    "hpo_state = \"InProgress\"\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "while hpo_state == \"InProgress\":\n",
    "    hpo_state = smclient.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "    print(\"-\", end=\"\")\n",
    "    time.sleep(60)  # Poll once every 1 min\n",
    "\n",
    "print(\"\\nHPO state:\", hpo_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "Just like with our `estimator`, we can call `tuner.deploy()` to create an endpoint and `predictor` from the best-performing model found in the HPO run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "In this notebook, we refactored our local code to train and deploy the same Keras model using SageMaker.\n",
    "\n",
    "The benefits of this approach are:\n",
    "\n",
    "- We can automatically provision specialist computing resources (e.g. high-performance, or GPU-accelerated instances) for **only** the duration of the training job: Getting good performance in training, without leaving resources sitting around under-utilized\n",
    "- Our trained model can be deployed to a secure, production-ready web endpoint with just one SDK call: No container or web application packaging required, unless we want to customize the behaviour\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
