{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601993bd-1607-4def-8217-8a405dca9bcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Direct Marketing in Banking - Propensity Modelling with Tabular Data\n",
    "\n",
    "# Part 2: XGBoost and Hyperparameter Optimization\n",
    "\n",
    "> *This notebook works well with the `Python 3 (Data Science 3.0)` kernel on SageMaker Studio*\n",
    "\n",
    "This workshop explores a tabular, [binary classification](https://en.wikipedia.org/wiki/Binary_classification) use-case with significant **class imbalance**: predicting which of a bank's customers are likely to respond to a targeted marketing campaign.\n",
    "\n",
    "In this second notebook, you'll tackle the challenge with the [SageMaker built-in XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) and [automatic hyperparameter tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html).\n",
    "\n",
    "> ⚠️ **You must** have run [Notebook 1 Autopilot and AutoGluon.ipynb](1%20Autopilot%20and%20AutoGluon.ipynb) before this notebook (at least to the point of having queried a data snapshot from SageMaker Feature Store)\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "> ℹ️ **Tip:** You can use the Table of Contents panel in the left sidebar on JupyterLab / SageMaker Studio, to view and navigate sections\n",
    "\n",
    "1. **[Prepare our environment](#Prepare-our-environment)**\n",
    "1. **[Understand the algorithm requirements](#Understand-the-algorithm-requirements)**\n",
    "1. **[Prepare training and test data](#Prepare-training-and-test-data)**\n",
    "1. **[Train a model](#Train-a-model)**\n",
    "1. **[Batch inference](#Batch-inference)**\n",
    "1. **[Hyperparameter Optimization (HPO)](#Hyperparameter-Optimization-(HPO))**\n",
    "1. **[Deploy and test the optimized model](#Deploy-and-test-the-optimized-model)**\n",
    "1. **[Conclusions](#Conclusions)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b71f36-4f16-4d1e-99ef-3bfd168b502e",
   "metadata": {},
   "source": [
    "## Prepare our environment\n",
    "\n",
    "As in the previous notebook, we'll start by importing libraries and configuring AWS/Sagemaker service connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcecf6b9-d086-4d2f-b5b3-5af0678dc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import json\n",
    "import time\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General-purpose AWS SDK for Python\n",
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # Tabular data utilities\n",
    "import sagemaker  # High-level SDK specifically for Amazon SageMaker\n",
    "\n",
    "# Local Helper Functions:\n",
    "import util\n",
    "\n",
    "# Setting up SageMaker parameters\n",
    "sgmk_session = sagemaker.Session()  # Connect to SageMaker APIs\n",
    "region = sgmk_session.boto_session.region_name  # The AWS Region we're using (e.g. 'ap-southeast-1')\n",
    "bucket_name = sgmk_session.default_bucket()  # Select an Amazon S3 bucket\n",
    "bucket = boto3.resource(\"s3\").Bucket(bucket_name)\n",
    "bucket_prefix = \"sm101/direct-marketing\"  # Location in the bucket to store our files\n",
    "sgmk_role = sagemaker.get_execution_role()  # IAM Execution Role to use for permissions\n",
    "\n",
    "print(f\"s3://{bucket_name}/{bucket_prefix}\")\n",
    "print(sgmk_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c9f00-e6d2-4919-9818-259f33fb7773",
   "metadata": {},
   "source": [
    "## Understand the algorithm requirements\n",
    "\n",
    "As discussed on the [XGBoost algorithm doc page](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html), there are 2 ways to use XGBoost in SageMaker: As a pre-built algorithm (no script required), or as a framework (with your own custom training script).\n",
    "\n",
    "In this example, we'll use pre-built algorithm mode so only need to fetch the container image URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0d5df-16ba-4d30-a883-febf7210fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.5-1\")\n",
    "print(train_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aba13d-367c-447c-bc4b-b88dccf8901b",
   "metadata": {},
   "source": [
    "## Prepare training and test data\n",
    "\n",
    "We'll **re-use the snapshot** queried from SageMaker Feature Store in the previous notebook, reading all CSVs under the S3 prefix into a combined dataframe.\n",
    "\n",
    "▶️ **Check** the `data_extract_s3uri` here matches your `data_extract_s3uri` from notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf456b1a-5980-4789-88cb-4aa21a8fc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extract_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/data-extract\"\n",
    "data_extract_prefix = data_extract_s3uri[len(\"s3://\"):].partition(\"/\")[2]\n",
    "\n",
    "full_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f\"s3://{s3obj.bucket_name}/{s3obj.key}\")\n",
    "        for s3obj in bucket.objects.filter(Prefix=data_extract_prefix)\n",
    "        if s3obj.key.lower().endswith(\".csv\")\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3519567-e0c6-41e5-bb47-c323debf8ee6",
   "metadata": {},
   "source": [
    "However, some extra data preparation is required because (at the time of writing), this XGBoost algorithm version doesn't fully support string categorical features.\n",
    "\n",
    "Below we **one-hot encode the categorical fields** before splitting the data into train and test sets as done previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b662d36-7e35-4cb2-9dc1-d80376386b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_data = full_df.drop(\n",
    "    columns=[\n",
    "        \"customer_id\", \"event_time\", \"write_time\", \"api_invocation_time\", \"is_deleted\", \"row_number\"\n",
    "    ],\n",
    "    errors=\"ignore\",  # Your DF may not have 'row_number' if you didn't do a time travel query\n",
    ")\n",
    "df_model_data\n",
    "\n",
    "# Need to one-hot encode?\n",
    "df_model_data = pd.get_dummies(df_model_data)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "# Shuffle and splitting dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_model_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    ")\n",
    "\n",
    "# Create CSV files for Train / Validation / Test\n",
    "train_data.to_csv(\"data/train.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"data/validation.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"data/test.csv\", index=False, header=False)\n",
    "\n",
    "df_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48294f9-cdb8-402d-bdd8-43fda8f9117a",
   "metadata": {},
   "source": [
    "The datasets specific for this algorithm can then be uploaded to Amazon S3, similar to with AutoGluon-Tabular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647af3b-78e1-491e-a98a-d4af7472a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/model-data-xgb\"\n",
    "\n",
    "train_data_s3uri = model_data_s3uri + \"/train/data.csv\"\n",
    "train_data.to_csv(train_data_s3uri, index=False, header=False)\n",
    "validation_data_s3uri = model_data_s3uri + \"/validation/data.csv\"\n",
    "validation_data.to_csv(validation_data_s3uri, index=False, header=False)\n",
    "test_data_s3uri = model_data_s3uri + \"/test/data.csv\"\n",
    "test_data.to_csv(test_data_s3uri, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e6833-1a31-464c-a27f-7b533eba1074",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "With the parameters collected and data prepared in a compatible format, we're ready to train an initial model.\n",
    "\n",
    "Like in the previous AutoGluon example, this process uses the [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator) SDK class to define and run the training job.\n",
    "\n",
    "Unlike the AutoGluon example:\n",
    "\n",
    "- The XGBoost algorithm expects separate `train` and `validation` channels instead of folders under a single `training` prefix\n",
    "- We'll demonstrate using [SageMaker managed spot](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) to save cost, since this algorithm can train on a more basic CPU-only instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717597e0-ee03-4f33-86e2-afaf3aa39e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    base_job_name=\"xgboost\",\n",
    "    role=sgmk_role,  # IAM role for job permissions\n",
    "    image_uri=train_image_uri,  # AutoGluon-Tabular algorithm container\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",  # Type of compute instance\n",
    "    max_run=25 * 60,  # Limit job to 25 minutes\n",
    "    \n",
    "    use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    max_wait=30 * 60,  # Maximum clock time (including spot delays)\n",
    "\n",
    "    output_path=f\"s3://{bucket_name}/{bucket_prefix}/train-output\",\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    num_round=50,  # int: [1,300]\n",
    "    max_depth=5,  # int: [1,10]\n",
    "    alpha=2.5,  # float: [0,5]\n",
    "    eta=0.5,  # float: [0,1]\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Training job by passing the S3 path of the datasets:\n",
    "xgb_estimator.fit({\n",
    "    \"train\": sagemaker.inputs.TrainingInput(train_data_s3uri, content_type=\"csv\"),\n",
    "    \"validation\": sagemaker.inputs.TrainingInput(validation_data_s3uri, content_type=\"csv\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22699245-8099-4dc9-8c55-be4b2d610cda",
   "metadata": {},
   "source": [
    "## Batch inference\n",
    "\n",
    "In the previous notebook we deployed our model to a real-time endpoint and made inference requests to test its accuracy - before shutting the endpoint down to release the infrastructure.\n",
    "\n",
    "But SageMaker can instead orchestrate batch inference for us with [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html): spinning up a temporary cluster and shutting it down as soon as all the input data is processed.\n",
    "\n",
    "To get started, you can create a [Transformer object](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) directly from `estimator.transformer(...)`. However, in this example we'll go via `create_model()` first so we can easily register the model later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecdae4-2d56-48ec-8514-146a5046ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb_estimator.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96377c5-73b2-4e3f-bfcf-c0169094aff6",
   "metadata": {},
   "source": [
    "Because SageMaker Batch Transform orchestrates the process of sending the data through the endpoint and consolidating the outputs, there are a range of extra parameters beyond the basic output location and instance size/type.\n",
    "\n",
    "By default, SageMaker Batch Transform treats each file in the input S3 prefix as one request payload and generates an output file of the same name, appending `.out`. Below we configure more specific handling for tabular data though:\n",
    "\n",
    "- Interpret each line of input files as a separate record with `split_type`, and interpret each line of output data as separate record with `assemble_with`.\n",
    "- Make `MultiRecord` batch requests up to `max_payload` Megabytes each - allowing up to `max_concurrent_transforms` concurrent requests per instance.\n",
    "- Exclude the `y` target label column (which is present in the test data) from model requests with `input_filter`.\n",
    "- Include the input data as well as the predictions in the result with `join_source`.\n",
    "\n",
    "The result will still be a single `.csv.out` file for each `.csv` input, but SageMaker has control of individual request batch sizes to optimize resource use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88304a6-8477-4e1f-83cb-0f031868ee6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/xgb-evaluation\"\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(\n",
    "    output_path=eval_s3uri,  # S3 output location\n",
    "    instance_count=1,  # Number of instances to spin up for the job\n",
    "    instance_type=\"ml.m5.large\",  # Instance type to use for inference\n",
    "    strategy=\"MultiRecord\",  # Request inference in batches, for efficiency\n",
    "    accept=\"text/csv\",  # Request CSV response format\n",
    "    assemble_with=\"Line\",  # Consolidate response records with newlines between\n",
    "    max_concurrent_transforms=2,  # Instances sent up to N requests concurrently\n",
    "    max_payload=1,  # Max size per request (in Megabytes)\n",
    ")\n",
    "\n",
    "xgb_transformer.base_transform_job_name=\"sm101-dm-xgboost\"\n",
    "xgb_transformer.transform(\n",
    "    test_data_s3uri,\n",
    "    content_type=\"text/csv\",  # Test data is in CSV format\n",
    "    split_type=\"Line\",  # Each line of test data is a separate record\n",
    "    join_source=\"Input\",  # Output joined data including the input features as well as prediction\n",
    "    input_filter=\"$[1:]\",  # Exclude the leading (actual target value) field\n",
    "    # wait=True,  # (Default True) Block the notebook kernel until the job completes\n",
    "    # logs=True,  # (Default True) Stream job logs to the notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a46cd-d2c8-46c0-a49d-619953b7edbe",
   "metadata": {},
   "source": [
    "Once the job completes, we can read the dataframe direct from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa6cad-a63f-4454-aea3-7f5c978a3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(\n",
    "    eval_s3uri + \"/data.csv.out\",\n",
    "    header=None,\n",
    "    names=test_data.columns.tolist() + [\"y_prob\"],\n",
    ")\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a634aa4-a413-48bf-b32a-48174190156a",
   "metadata": {},
   "source": [
    "This algorithm only outputs positive-class probability scores for binary classification - not including assigned class labels like AutoGluon-Tabular.\n",
    "\n",
    "For assessing performance we can either assume a particular `decision_threshold` (for example, scores over than 0.5 are assigned to class 1) - or take whatever threshold maximises the F1 score of the model.\n",
    "\n",
    "Run the cell below to produce a model quality report similar to our AutoGluon-Tabular example earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ac6c-dd50-4c26-8484-7d681bb0a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = util.reporting.generate_binary_classification_report(\n",
    "    y_real=df_eval[\"y\"].values,\n",
    "    y_predict_proba=df_eval[\"y_prob\"].values,\n",
    "    # y_predict_label not available for XGBoost output format\n",
    "    # Optionally set decision_threshold=0.5 to apply a specific threshold, instead of maximizing F1:\n",
    "    # decision_threshold=0.5,\n",
    "    class_names_list=[\"Did not enroll\", \"Enrolled\"],\n",
    "    title=\"Initial XGBoost model\",\n",
    ")\n",
    "\n",
    "# Store the model quality report locally and on Amazon S3:\n",
    "with open(\"data/report-xgboost.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "model_quality_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/{xgb_model.name}/model-quality.json\"\n",
    "!aws s3 cp data/report-xgboost.json {model_quality_s3uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6b4a7-3ae1-430f-ad93-dfccfdd16fe6",
   "metadata": {},
   "source": [
    "We can register this alternative model as a new **version** in the same **model package group** from earlier, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199e4e7-7f86-4076-b974-3c0bacc6c9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    model_package_group_name=\"sm101-dm\",\n",
    "    description=\"Initial XGBoost model\",\n",
    "    model_metrics=sagemaker.model_metrics.ModelMetrics(\n",
    "        model_statistics=sagemaker.model_metrics.MetricsSource(\n",
    "            content_type=\"application/json\",\n",
    "            s3_uri=model_quality_s3uri,\n",
    "        ),\n",
    "    ),\n",
    "    domain=\"MACHINE_LEARNING\",\n",
    "    task=\"CLASSIFICATION\",\n",
    "    sample_payload_url=test_data_s3uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12fc3b-df90-44d5-accb-c6e4a6640c8c",
   "metadata": {},
   "source": [
    "▶️ **Open** your model group in SageMaker Model Registry\n",
    "\n",
    "- You can `Shift+Click` or `Control+Click` to **select multiple versions** in the model group\n",
    "- With multiple versions selected, you can `Right Click` to `Compare model versions` for a side-by-side comparison of different models' charts and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ec0e0-1bde-4121-b738-7e63bad4c151",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization (HPO)\n",
    "\n",
    "> ⏰ *Note, with the default settings below, the hyperparameter tuning job can take up to ~20 minutes to complete.*\n",
    "\n",
    "While AutoML frameworks like AutoGluon try to encapsulate model ensembling, single-algorithm approaches like XGBoost can often benefit from **hyperparameter tuning** to find the best values for settings like `alpha`, `eta` and `max_depth` on a particular problem.\n",
    "\n",
    "Exploring these parameter combinations by hand can be time-consuming - especially if considering more than a couple of parameters.\n",
    "\n",
    "[SageMaker automatic model tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) can run intelligent exploration and optimization jobs for you automatically, so you can focus on building and applying insights - rather than managing these experiments.\n",
    "\n",
    "As shown below, you can set up a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) wrapper around your standard `Estimator`. The key requirements are:\n",
    "\n",
    "1. Your job outputs at least one **metric** which the tuner can maximize or minimize (this is handled automatically for most built-in algorithms)\n",
    "1. Specify **ranges for the hyperparameters** you'd like to explore\n",
    "1. Specify the **strategy and resource limits** for the job\n",
    "\n",
    "SageMaker HPO supports a range of [strategies](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) including exploratory tools like Grid and Random search, and efficient HPO-oriented optimization tools like Bayesian Optimization and Hyperband.\n",
    "\n",
    "In this example, we'll use Bayesian search to optimize Area Under the ROC Curve (AUC) of our XGBosot model [See Machine Learning Key Concepts](https://docs.aws.amazon.com/machine-learning/latest/dg/amazon-machine-learning-key-concepts.html) for more info if you're unfamiliar with these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e82c2-6c74-48d8-a705-67623cb8753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required HPO objects\n",
    "from sagemaker.tuner import (\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    ")\n",
    "\n",
    "# Target metric is already built in to the algorithm, so we just specify the name:\n",
    "objective = \"validation:auc\"\n",
    "\n",
    "# Configure hyperparameter ranges to explore:\n",
    "ranges = {\n",
    "    \"num_round\": IntegerParameter(1, 300),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 5),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "}\n",
    "\n",
    "# Configure the tuner:\n",
    "xgb_tuner = HyperparameterTuner(\n",
    "    estimator=xgb_estimator,  # The SageMaker estimator object\n",
    "    hyperparameter_ranges=ranges,\n",
    "    max_jobs=15,  # Max total number of training jobs\n",
    "    max_parallel_jobs=3,  # How many training jobs can run in parallel\n",
    "    strategy=\"Bayesian\",  # the internal optimization strategy of HPO\n",
    "    objective_metric_name=objective,\n",
    "    objective_type=\"Maximize\",  # For AUC, higher = better\n",
    ")\n",
    "\n",
    "# Start the job:\n",
    "xgb_tuner.fit(\n",
    "    {\n",
    "        \"train\": sagemaker.inputs.TrainingInput(train_data_s3uri, content_type=\"csv\"),\n",
    "        \"validation\": sagemaker.inputs.TrainingInput(validation_data_s3uri, content_type=\"csv\"),\n",
    "    },\n",
    "    wait=True,  # Optionally block the notebook until the job is complete.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bbc090-347f-41a3-ac86-0eeb7ec167f8",
   "metadata": {},
   "source": [
    "Note that `max_parallel_jobs` creates a trade-off between job run time and result quality: The more jobs are run in parallel, the faster the `max_jobs` will be completed, but the less information the strategy has about completed jobs when selecting parameter combinations to try next.\n",
    "\n",
    "As with training and transform jobs, hyperparameter tuning runs separately from the notebook so won't be interrupted if you lose connection or shut down. You can track job progress in the [Training > Hyperparameter tuning jobs page](https://console.aws.amazon.com/sagemaker/home?#/hyper-tuning-jobs) of the SageMaker console and the [DescribeHyperParameterTuningJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeHyperParameterTuningJob.html).\n",
    "\n",
    "You can always set `wait=False` or interrupt the cell (Square stop ⏹ button in the toolbar) to continue working in the notebook while HPO runs in the background. You can later resume waiting for the active job by calling `tuner.wait()` as shown below. Just like the Estimator, you won't be able to `deploy()` the tuner's model until the tuning job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d2402-9175-42ab-b909-c09ed7b3c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef102a-109d-48ae-93ab-e3b4d4c75811",
   "metadata": {},
   "source": [
    "The individual training jobs created by the model tuning are listed in SageMaker just like manually-created ones, and the HPO job builds up a leaderboard of models based on the objective metric.\n",
    "\n",
    "In this example we'll simply deploy the \"best\" model, but you can also explore the jobs for deeper insights: See [this sample notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) for examples.\n",
    "\n",
    "\n",
    "## Deploy and test the optimized model\n",
    "\n",
    "You can directly call the [HyperparameterTuner.deploy(...)](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html#sagemaker.tuner.HyperparameterTuner.deploy) method to deploy the winning model to an endpoint - but as before, we'll create a `Model` object first to link back to SageMaker Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530540a-2438-46a9-a0af-913e36c92556",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job_name = xgb_tuner.best_training_job()\n",
    "print(\"Best training job from HPO run:\", best_job_name)\n",
    "\n",
    "hpo_model = sagemaker.estimator.Estimator.attach(best_job_name).create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e4504-5d1f-41f1-a58f-b04dd13c4f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hpo_predictor = hpo_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cabc55-8113-4b8b-b1ec-b0bbce6aad2f",
   "metadata": {},
   "source": [
    "Once deployed, we can evaluate the performance by sending real-time inference requests as before with AutoGluon.\n",
    "\n",
    "Remember that the output of this algorithm is different: in CSV format with only the positive class probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f12dab-bddd-40c9-a176-262ad35160bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predicted probabilities of the best model\n",
    "hpo_probabilities = np.array(\n",
    "    hpo_predictor.predict(test_data.drop([\"y\"], axis=1).values),\n",
    "    dtype=float,\n",
    ").squeeze()\n",
    "\n",
    "hpo_report = util.reporting.generate_binary_classification_report(\n",
    "    y_real=test_data[\"y\"].values,\n",
    "    y_predict_proba=hpo_probabilities,\n",
    "    # y_predict_label not available for XGBoost output format\n",
    "    # Optionally set decision_threshold=0.5 to apply a specific threshold, instead of maximizing F1:\n",
    "    # decision_threshold=0.5,\n",
    "    class_names_list=[\"Did not enroll\", \"Enrolled\"],\n",
    "    title=\"HP-tuned XGBoost model\",\n",
    ")\n",
    "\n",
    "# Store the model quality report locally and on Amazon S3:\n",
    "with open(\"data/report-xgbhpo.json\", \"w\") as f:\n",
    "    json.dump(hpo_report, f, indent=2)\n",
    "hpo_quality_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/{hpo_model.name}/model-quality.json\"\n",
    "!aws s3 cp data/report-xgbhpo.json {hpo_quality_s3uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180230d-1f3f-4541-980e-71f67c93a10a",
   "metadata": {},
   "source": [
    "...And finally, we can register this tuned model as a third candidate version in our SageMaker Model Registry group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca13456-796b-4522-b5dd-f7785a603634",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    model_package_group_name=\"sm101-dm\",\n",
    "    description=\"HP-tuned XGBoost model\",\n",
    "    model_metrics=sagemaker.model_metrics.ModelMetrics(\n",
    "        model_statistics=sagemaker.model_metrics.MetricsSource(\n",
    "            content_type=\"application/json\",\n",
    "            s3_uri=hpo_quality_s3uri,\n",
    "        ),\n",
    "    ),\n",
    "    domain=\"MACHINE_LEARNING\",\n",
    "    task=\"CLASSIFICATION\",\n",
    "    sample_payload_url=test_data_s3uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82ce66-d3b3-49ce-b2ff-f577b9a72e5a",
   "metadata": {},
   "source": [
    "You can compare the model charts and statistics side-by-side in SageMaker Studio's Model Registry UI to assess their performance - as shown in the screenshot below:\n",
    "\n",
    "![](img/model-registry-compare.png \"Screenshot of side-by-side comparison in SageMaker Studio Model Registry UI\")\n",
    "\n",
    "Note that:\n",
    "\n",
    "- F1-related comparisons may not be entirely fair: Our XGBoost models' metrics automatically inferred the F1-maximising threshold and used it to drive decisions, whereas AutoGluon-Tabular used its own threshold selection algorithm to assign labels.\n",
    "- This model package group can contain versions with different I/O contracts (Our XGBoost models expect one-hot encoded inputs, and our AutoGluon model produces JSON output instead of CSV). You could consider also attaching [data quality reports](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html) to fully specify the expected distribution of model inputs and outputs from training, and attaching additional lineage metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c24ff-cf6d-49ac-811d-d2974a734d3a",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this example we used an alternative built-in algorithm for tabular data on SageMaker, and showed how its performance can be improved by efficient, [automatic hyperparameter tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) without manually exploring combinations.\n",
    "\n",
    "We used a relatively small number of trials in this HPO run to keep the run-time fast, so you might not have seen much improvement: But HPO is particularly useful when the space of parameters becomes large and you can allocate sufficient compute resources for the algorithm to explore best combinations for you.\n",
    "\n",
    "Although [SageMaker Autopilot](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development.html) is perhaps the quickest way to deliver strong initial results on a new tabular data project, SageMaker built-in algorithms support a wide range of use-cases from text and vision to more niche tabular problem types. Combining built-in algorithms with SageMaker HPO can really boost their accuracy.\n",
    "\n",
    "In fact, you'll see that Autopilot uses many of these same tools under the hood: Creating HPO jobs when running in HPO mode, using SageMaker Processing for data pre-processing experiments, and making use of the XGBoost and AutoGluon-Tabular algorithms.\n",
    "\n",
    "Check out the other workshops in this repository to dive deeper on custom ML with bring-your-own-script training jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7c449-4c89-4307-b952-e34cc1a40f16",
   "metadata": {},
   "source": [
    "## Releasing cloud resources\n",
    "\n",
    "As mentioned in the previous notebook, you should shut down any created inference endpoints when finished experimenting. You may also choose to clear out your Amazon S3 storage, in which case do remember to delete your SageMaker Feature Store Feature Group and Model Registry Model Group first.\n",
    "\n",
    "You can un-comment the below code to delete the inference endpoint created by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64a6ee-4bef-49fb-bd0c-fc1861c709d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hpo_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
